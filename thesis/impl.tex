\documentclass[index]{subfiles}
\begin{document}
\chapter{自动化设计系统的实现}\label{sec:impl}
本章将在\cref{sec:design}对系统的顶层设计的基础上，重点讨论每个组件的具体设计与实现细节，并介绍具体软件实现中所采用的技术栈。

对于较为大型的软件系统，除了开发系统本身以外，还需要单独开发另一套系统，用以对实际系统进行时时刻刻的监控，以方便运维人员应对可能出现的异常情况。
本章将先介绍自动化设计系统的本身（应用面子系统，面向用户）的实现细节，再简要介绍内部监控系统（控制面子系统，并不面向用户）的架构，
最后采用UML部署图画出整个系统的物理视图，讨论各个组件之间的通信方法，并描述整个系统的最终实现成果。

\section{应用面子系统的细化设计与开发}
本节将就\cref{fig:design-comp}中的每个组件分别讨论技术栈选型和设计实现的全部细节。

在\cref{fig:design-comp}中，状态存储和消息队列两个组件和其他组件存在显著不同——它们都已经有了非常成熟的开源软件实现。
对于状态存储，本文选用开源分布式强一致性键值数据库etcd作为实现，其对外提供了读取、写入、擦除、监控修改等等一系列功能，
可以满足\cref{fig:design-comp}中对状态存储组件的要求。

对于消息队列，本文选用基于Erlang语言的开源分布式消息队列RabbitMQ作为实现，其遵守AMQP协议，且对外提供了队列运行监控功能。
通过将其内部结构配置成\cref{fig:design-comp-mq}所示的样子，就可以满足\cref{fig:design-comp}中对消息队列组件的要求。

\subsection{文件存储}
\begin{figure}[h]
  \centering
  \includegraphics{./figures/dist/impl-storage-usecase.pdf}
  \caption[文件存储组件的行为]{使用UML用户用例图描绘文件存储组件的行为。\label{fig:impl-storage-usecase}}
\end{figure}
\begin{figure}[h]
  \centering
  \includegraphics{./figures/dist/impl-storage-package.pdf}
  \caption[文件存储组件的结构]{使用UML包图描绘文件存储组件的结构。\label{fig:impl-storage-package}}
\end{figure}
通过将\cref{fig:design-comp}中对文件存储组件的要求细化，可以得到\cref{fig:impl-storage-usecase}。
具体来说，文件存储组件对外提供一套HTTP API，根据HTTP动词和URL来对硬盘上的指定资源进行指定操作，如上传、下载、移动等等。
之所以要区分两种不同的上传，是因为需要对用户上传的仿真源文件进行重命名，使得文件名相同的文件内容相同，文件名不同的文件文件内容不同，
以保证\cref{sec:design-wf}中提到的对Ansys结果的缓存可以正确工作。

本文选取JavaScript语言进行程序编写，目录结构如\cref{fig:impl-storage-package}所示，其中主要文件的功能如下：
\begin{description}
  \item[logger.js] 将日志信息汇总至Logstash（见\cref{sec:impl-elk}）
  \item[file/common.js] 判断文件名是否合法
  \item[file/get.js] 响应GET请求，实现文件下载、列出文件夹内容、打包下载文件夹
  \item[file/post.js] 响应POST请求，实现源文件上传、仿真结果上传
  \item[file/put.js] 响应PUT请求，方便调试时上传文件
  \item[utils/contentstream.js] 对HTTP PUT请求的内容进行解析
  \item[utils/disk.js] 对用户上传的仿真源文件进行重命名
\end{description}

\subsection{工作流内核}
\begin{figure}[h]
  \centering
  \includegraphics{./figures/dist/impl-controller-seq.pdf}
  \caption[工作流内核组件的行为]{使用UML序列图描绘工作流内核组件的行为。\label{fig:impl-controller-seq}}
\end{figure}
\begin{figure}[h]
  \centering
  \includegraphics{./figures/dist/impl-controller-package.pdf}
  \caption[工作流内核组件的结构]{使用UML包图描绘工作流内核组件的结构。\label{fig:impl-controller-package}}
\end{figure}
根据\cref{ssec:design-wf}中对工作流内核组件的描述，该组件虽然不对外提供服务，但内部却存在较为复杂的流程。
为此，采用UML序列图而非UML用户用例图来对该组件的行为进行建模。
\Cref{fig:impl-controller-seq}详细描述了工作流内核如何实现FL-Petri网的运行，其中的跳变表示FL-Petri网中的跳变，而非其翻译之后的L-Petri网的跳变。
解释器在收到消息队列中的外部事件（其中注明了应尝试启功哪个外部跳变）以后，首先会为本次消息处理创建一个运行环境。
运行环境中最重要的属性是Petri网名称（因为状态存储中不仅仅存储了一张Petri网）和当前跳变的层参数。
随后，解释器通过运行环境检查当前跳变的输入是否满足（正常情况下由外部事件直接触发的外部跳变的输入应该满足，否则多是因为网络抖动等原因导致同一任务有多个应答）。
若满足，则执行该外部跳变。在执行过程中，
可以对数据库中不涉及状态的字段进行读写，以保存中间结果以供后续使用；
可以向消息队列发布计算任务（对于简单的表达式计算，甚至可以直接发布计算结果）；
还可以调用运行环境中相应的方法来设置跳变的输出（位置和层参数）。
在跳变执行完毕以后，解释器检查运行环境中发生变化的F-Petri网位置，并尝试检查以之为输入的内部跳变的输入是否满足；
若满足，则执行那些内部跳变。重复以上过程，直至所有F-Petri网中的跳变均不满足输入条件。
最后，通知运行环境将上述所有修改批量写入数据库，并通知消息队列该事件已经妥善处理完毕。

需要注意的是，该工作流内核并不是一个完整的FL-Petri网的模拟器（甚至也不是完整的Petri网模拟器）：
\begin{itemize}
  \item 无法处理对于没有输入弧的内部跳变
  \item 无法处理多个内部跳变无限循环的情况
  \item 无法正确处理多个跳变完全竞争的情形（在实现中为了简单起见，名字靠前的跳变会被执行）
\end{itemize}
然而，这些缺陷并不影响其作为工作流引擎——在本文所述系统的工作流\cref{fig:design-petri1,fig:design-petri2}中，以上三种情况根本不存在。

特别值得一提的是，关于工作流中使用LHSMDU算法进行初始化和使用贝叶斯优化算法计算下一步迭代位置，
工作流内核组件并不负责具体算法实现，而仅仅是发出相应的计算任务（调用LHSMDU算法为Python计算任务，调用贝叶斯优化算法为R语言计算任务）。

本文选取JavaScript语言进行程序编写，目录结构如\cref{fig:impl-controller-package}所示，其中主要文件的功能如下：
\begin{description}
  \item[amqp.js] 消息队列驱动
  \item[etcd.js, adapter.js] 数据库驱动
  \item[core/global.js] 最外层的FL-Petri网跳变
  \item[core/category.js] 分类层的FL-Petri网跳变中的初始化和收尾部分
  \item[core/iter.js] 分类层的FL-Petri网跳变中的迭代部分
  \item[core/eval.js] 求值层和参数层的FL-Petri网跳变中的参数计算部分
  \item[core/ansys.js] 求值层的FL-Petri网跳变中的Ansys仿真部分
  \item[petri/index.js] FL-Petri网解释器
  \item[petri/path.js] 负责层参数的序列化和反序列化
  \item[petri/runtime.js] 运行环境
\end{description}

\subsection{计算服务}
\begin{figure}[h]
  \centering
  \includegraphics{./figures/dist/impl-commond-activity.pdf}
  \caption[计算服务组件的行为]{使用UML活动图描绘计算服务组件的行为。\label{fig:impl-commond-activity}}
\end{figure}
\begin{figure}[h]
  \centering
  \includegraphics{./figures/dist/impl-commond-package.pdf}
  \caption[计算服务组件的结构]{使用UML包图描绘计算服务组件的结构。\label{fig:impl-commond-package}}
\end{figure}
根据\cref{ssec:design-wf}中对计算服务组件的描述，该组件并不对外提供服务，且其内部流程也比较简单。
为此，采用UML活动图而非UML用户用例图或UML序列图来对该组件的行为进行建模，如\cref{fig:impl-commond-activity}所示。
图中只表明了如何处理Ansys仿真任务；
对于其他计算任务（Python、R、Mathematica等），基本流程几乎完全一致，只是少了下载仿真文件和上传仿真结果文件两步。

实际上，计算服务组件虽然从行为上看仅仅是调用其他程序执行相应代码，但在结构上还需注意一个特殊的问题：
这些代码可能包括一些依赖项，比如其执行的Python计算任务可能包括调用LHSMDU算法，R语言计算任务可能包括调用贝叶斯优化算法。
为此，本文除了选取Go语言进行主体程序编写以外，还分别使用Python语言和R语言封装/实现了LHSMDU和贝叶斯优化算法。
最终包结构如\cref{fig:impl-commond-package}所示
（commond/python、commond/rlang、commond/mma、commond/ansys四个包的内容几乎完全相同，故只画出一个），
其中主要文件和包的功能如下：
\begin{description}
  \item[commond-std] 将commond封装成可以独立运行的程序
  \item[commond-svc] 将commond封装成Windows服务，以便在Windows系统上长时间运行
  \item[common/util.go] 封装创建临时文件夹、实时监控日志文件、下载仿真文件、上传仿真结果文件、删除临时文件夹等功能
  \item[common/killer\_*.go] 结束进程树（分为Linux和Windows两个不同实现）
  \item[Python/doe.py] 进一步封装了LHSMDU算法提出者给出的Python实现\footnote{\href{https://github.com/sahilm89/lhsmdu}{https://github.com/sahilm89/lhsmdu}}
  \item[R/ei.R] 在R语言的GPfit包\cite{macdonald2015}、CEOptim包\cite{benham2015}的基础上，实现了\cref{sec:bgo}所描述的贝叶斯优化算法
\end{description}

\subsection{网站后端}
\begin{figure}[h]
  \centering
  \includegraphics{./figures/dist/impl-facade-usecase.pdf}
  \caption[网站后端组件的行为]{使用UML用户用例图描绘网站后端组件的行为。\label{fig:impl-facade-usecase}}
\end{figure}
\begin{figure}[h]
  \centering
  \includegraphics{./figures/dist/impl-facade-package.pdf}
  \caption[网站后端组件的结构]{使用UML包图描绘网站后端组件的结构。\label{fig:impl-facade-package}}
\end{figure}

通过将\cref{fig:design-comp}中对文件存储组件的要求细化，可以得到\cref{fig:impl-facade-usecase}。
具体来说，网站后端组件对外提供一套基于GraphQL的API，以对系统进行管理和监控。

本文选取JavaScript语言进行程序编写，目录结构如\cref{fig:impl-facade-package}所示，其中主要文件的功能如下：
\begin{description}
  \item[graphql/etcd.js] 读取当前状态
  \item[graphql/subscription.js] 监控状态改变
  \item[graphql/rabbit.js] 检查消息队列、清空消息队列
  \item[graphql/control.js] 中止任务、彻底删除任务
  \item[graphql/controller.js] 检查内核、重启内核
  \item[graphql/core.js] 发布/修改任务
\end{description}

\subsection{网站前端}
由于前端组件的功能异常简单（从网站后端获取数据并显示，将用户的指令传送到后端），故无需对其行为进行建模。
本文采用非常流行的React作为基础框架，采用Redux作为前端状态管理（保存用户当前访问的页面路径和填写中的表单），对网站前端进行程序编写。
网站虚拟（并非在部署时的文件结构，而是从用户角度来看的URL结构）结构如下：
\begin{description}
  \item[/] 网站首页，包括项目简介
  \item[/app] 控制面板，包括检查内核状态、检查消息队列、清空消息队列等功能
  \item[/app/run] 发布/修改任务
  \item[/app/upload] 上传仿真文件
  \item[/app/p/:proj] 项目监控，包括中止任务、彻底删除任务等功能
  \item[/app/p/:proj/cat/:cHash] 分类监控
  \item[/app/p/:proj/cat/:cHash/d/:dHash] 求值监控，包括仿真结果下载等功能
\end{description}

\section{控制面子系统的细化设计与开发}\label{sec:impl-elk}
\begin{figure}[h]
  \centering
  \includegraphics{./figures/dist/impl-elk-comp.pdf}
  \caption[控制面子系统的结构]{使用UML组件图描绘控制面子系统的结构。\label{fig:impl-elk-comp}}
\end{figure}
本文选取业界常用的ELK（Elasticsearch、Logstash、Kibana）作为系统监控、日志分析的解决方案，其结构如\cref{fig:impl-elk-comp}所示。
ELK架构中的核心是分布式搜索和数据分析引擎Elasticsearch，对外提供数据存储和搜索功能。
由于Elasticsearch只能处理结构化数据，故引入组件Logstash，将非结构化的日志信息进行预处理，再写入Elasticsearch中。
对于RabbitMQ、nginx等不支持将日志输送到Logstash的程序，需要先将日志写入文件，再将文件实时上传至Logstash进行分析；这一工作可以由Filebeat组件完成。
最后，Kibana组件提供了一套方便的基于Web的数据可视化控制面板，可以用图形界面非常直观地进行数据查询，以方便在系统出现问题后（尤其是横跨多个组件的疑难问题）进行调试诊断；
Elastalert组件（不属于ELK架构）则会定时对一些关键系统运行指标进行检索，一旦发现异常，会及时通知系统运维人员，以实现异常报警的功能。

\section{物理视图：系统部署方案}
本节讨论如何将前述所有组件（软件）部署在计算机（硬件）上，以使该系统真正运行起来。

\subsection{硬件设备简述}
为了方便系统开发，也为了从网络任意位置访问该系统，购买的小型云主机一台（Linux系统）；
为了进行非常消耗计算资源的Ansys仿真，租用工作站一台（Windows系统）。

\subsection{容器化与Docker}
容器化的基本思想同虚拟化一致：在一台物理机上运行多个组件时，将不同组件的运行环境隔离开，防止其互相干扰，也防止其干扰物理机（宿主）本身。
然而容器化在实现手段上和虚拟化有本质区别：
容器化为每个运行的组件开辟一个轻量级的虚拟环境——以文件目录为主，而虚拟化为每个运行的组件开辟一个重量级的虚拟环境——包含文件目录和全套操作系统。
虽然虚拟化更为安全可靠，计算性能也相比容器化更高，但在一台物理机上运行多个操作系统的开销非常巨大，运行维护也相对较为麻烦\cite{docker}。

经过多重考虑，本文在云服务器上采用docker——容器化思想的最成熟的开源实现——作为软件和硬件之间的沟通桥梁，以追求多次部署的灵活性；
在工作站上直接部署相关应用，以追求仿真计算时的极致性能。

\subsection{控制面子系统的部署}
首先，利用docker将\cref{sec:impl-elk}中提到的控制面子系统的5个组件部署在云服务器上。
其次，在所有硬件设备上部署Metricbeat服务，监听计算机CPU和内存占用情况，并将数据实时传送给Elasticsearch以供分析。
然后，考虑到Logstash服务启动时需要消耗大量的熵，故利用docker部署一个容器运行havaged算法
\footnote{\href{https://github.com/yorickdewid/Havaged}{https://github.com/yorickdewid/Havaged}}以提供足够的熵源，保证Logstash能够顺利启动。
最后，在云服务器（Linux）上部署Filebeat和JournalBeat服务，将Linux内核日志上传Logstash以供分析；
在工作站（Windows）上部署WinlogBeat服务，将Windows日志上传Elasticsearch以供分析。

\subsection{应用面子系统的部署}
首先，利用docker将消息队列（RabbitMQ）和状态存储（Etcd）部署在云服务器上。
由于Etcd采用分布式Raft算法，至少需要3个节点才能正常运行，故需部署etcd1、etcd2、etcd3共计三个docker容器。
其次，将文件存储、工作流内核、网站后端三个组件分别搭配JavaScript语言解释器——NodeJS，利用docker部署在云服务器上。
然后，为了将网站前端组件可靠地传送到用户的浏览器，将其与开源反向代理服务器——nginx——封装在同一个docker容器中，部署在云服务器上。
值得一提的是，从外部访问文件存储和网站后端时，实际上会经过nginx转发。这样做虽然会略微损失一点点性能，但在安全性、可维护性、灵活性上都得到了很大的提升，
是工程实际中常见的做法。

关于计算服务的部署值得详细讨论。首先，在工作站上应部署封装成Windows服务的计算服务组件实现（commond-svc），并妥当配置其调用Ansys仿真程序。
其次，将计算服务组件的独立运行版本（commond-std）、Python语言运行环境（已下载好相关的库）、Python语言编写的LHSMDU算法封装三者打包在一起，部署在云服务器上（称为pythond）；
同样，将commond-std、R语言运行环境、R语言编写的贝叶斯优化算法三者打包在一起，部署在云服务器上（称为rlangd）。

需要注意的是，虽然本文设计并实现了对Mathematica的支持，但由于其并非开源软件，无法将其封装在docker中部署在云服务器上。
若用户需要使用Mathematica，必须手动在装有Mathematica的计算机上配置并运行计算服务组件，以真正启用Mathematica支持。

\subsection{小结}
\begin{figure}[h]
  \centering
  \includegraphics{./figures/dist/impl-deploy.pdf}
  \caption[系统物理视图]{使用UML部署图描绘系统物理视图。\label{fig:impl-deploy}}
\end{figure}
\Cref{fig:impl-deploy}采用UML部署图的方法给出了整个自动化设计系统的物理视图。
自动化设计系统至此全部设计、开发、部署完毕。

\end{document}
